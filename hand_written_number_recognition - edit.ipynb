{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a tf.data.Dataset\n",
    "\n",
    "ds = tfds.load('mnist', split='train')\n",
    "# Data taken from MNIST dataset.\n",
    "\n",
    "batch_size = 10\n",
    "ds = ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE) # do .shuffle(buffer_size) to randomize batch set\n",
    "# Divides ds into batches of size batch_size\n",
    "\n",
    "# -- Note --\n",
    "# * All the data provided was used for training data,\n",
    "#   even though normally one would split the training data\n",
    "#   and the testing data and assess the Neural Network performance\n",
    "#   respcetively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the network\n",
    "\n",
    "num_first_layer = 100\n",
    "layer_1_weights = tf.Variable(tf.random.normal([num_first_layer, 784]), dtype = 'float32')\n",
    "layer_1_bias = tf.Variable(tf.random.normal([num_first_layer]), dtype = 'float32')\n",
    "output_layer_weights = tf.Variable(tf.random.normal([10, num_first_layer]), dtype = 'float32')\n",
    "output_layer_bias = tf.Variable(tf.random.normal([10]), dtype = 'float32')\n",
    "\n",
    "# --- Neural Network ---\n",
    "# * 784 input neurons, since image is 28 x 28\n",
    "# * First Layer consists of 100 Neurons\n",
    "# * Output Layer consists of 10 Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle :  1\n",
      "correct :  0.7335666666666667\n",
      "cycle :  2\n",
      "correct :  0.7418\n",
      "cycle :  3\n",
      "correct :  0.7470666666666667\n",
      "cycle :  4\n",
      "correct :  0.7515333333333334\n",
      "cycle :  5\n",
      "correct :  0.7562\n",
      "cycle :  6\n",
      "correct :  0.8168333333333333\n",
      "cycle :  7\n",
      "correct :  0.8337666666666667\n",
      "cycle :  8\n",
      "correct :  0.8398666666666667\n",
      "cycle :  9\n",
      "correct :  0.84345\n",
      "cycle :  10\n",
      "correct :  0.8471166666666666\n",
      "cycle :  11\n",
      "correct :  0.8649333333333333\n",
      "cycle :  12\n",
      "correct :  0.9247\n",
      "cycle :  13\n",
      "correct :  0.9310166666666667\n",
      "cycle :  14\n",
      "correct :  0.93455\n",
      "cycle :  15\n",
      "correct :  0.9376833333333333\n",
      "cycle :  16\n",
      "correct :  0.94015\n",
      "cycle :  17\n",
      "correct :  0.9415333333333333\n",
      "cycle :  18\n",
      "correct :  0.94375\n",
      "cycle :  19\n",
      "correct :  0.9451833333333334\n",
      "cycle :  20\n",
      "correct :  0.94675\n",
      "cycle :  21\n",
      "correct :  0.948\n",
      "cycle :  22\n",
      "correct :  0.9497\n",
      "cycle :  23\n",
      "correct :  0.9508166666666666\n",
      "cycle :  24\n",
      "correct :  0.9521\n",
      "cycle :  25\n",
      "correct :  0.9528666666666666\n",
      "cycle :  26\n",
      "correct :  0.9540166666666666\n",
      "cycle :  27\n",
      "correct :  0.9547333333333333\n",
      "cycle :  28\n",
      "correct :  0.9556166666666667\n",
      "cycle :  29\n",
      "correct :  0.95675\n",
      "cycle :  30\n",
      "correct :  0.957\n"
     ]
    }
   ],
   "source": [
    "# Training the Neural Network\n",
    "\n",
    "learning_rate = 0.1\n",
    "cycles = 30\n",
    "\n",
    "for j in range(cycles):\n",
    "    \n",
    "    for batch in ds:\n",
    "        with tf.GradientTape(persistent = True) as g:\n",
    "            error_func_over_examples = tf.constant(0, dtype = 'float32')\n",
    "            for i1 in range(batch['image'].shape[0]):\n",
    "\n",
    "                    g.watch(layer_1_weights)\n",
    "                    g.watch(layer_1_bias)\n",
    "                    g.watch(output_layer_weights)\n",
    "                    g.watch(output_layer_bias)\n",
    "\n",
    "                    test_image = tf.reshape(tf.image.convert_image_dtype(batch['image'][i1], dtype = 'float32'), 784)\n",
    "\n",
    "                    network_1 = tf.math.sigmoid(tf.tensordot(layer_1_weights,  test_image , axes = 1) + layer_1_bias)\n",
    "                    network_2 = tf.math.sigmoid(tf.tensordot(output_layer_weights, network_1, axes = 1) + output_layer_bias)\n",
    "\n",
    "                    test_label = [0 if k != batch['label'][i1] else 1 for k in range(10)]\n",
    "                    test_label = tf.constant(test_label, dtype = 'float32')\n",
    "                    error_func = tf.reduce_sum((test_label - network_2) ** 2) # This is the distance from the actual answer\n",
    "                    error_func_over_examples += (error_func / 10) # Every iteratio we add over the examples\n",
    "                    \n",
    "\n",
    "        layer_1_weights.assign_add(- g.gradient(error_func_over_examples, layer_1_weights) * learning_rate)\n",
    "        layer_1_bias.assign_add(- g.gradient(error_func_over_examples, layer_1_bias) * learning_rate)\n",
    "        output_layer_weights.assign_add(-g.gradient(error_func_over_examples, output_layer_weights) * learning_rate)\n",
    "        output_layer_bias.assign_add(-g.gradient(error_func_over_examples, output_layer_bias) * learning_rate)\n",
    "        \n",
    "        \n",
    "        \n",
    "    correct_count = 0\n",
    "    for batch in ds:\n",
    "        for i1 in range(batch['image'].shape[0]):\n",
    "            test_image = tf.reshape(tf.image.convert_image_dtype(batch['image'][i1], dtype = 'float32'), 784)\n",
    "            network_1 = tf.math.sigmoid(tf.tensordot(layer_1_weights,  test_image , axes = 1) + layer_1_bias)\n",
    "            network_2 = tf.math.sigmoid(tf.tensordot(output_layer_weights, network_1, axes = 1) + output_layer_bias)\n",
    "            if tf.argmax(network_2).numpy() == batch['label'][i1].numpy():\n",
    "                correct_count += 1\n",
    "    print('cycle : ', j + 1)\n",
    "    print('correct : ', correct_count / 60000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights and biases from npy file\n",
    "\n",
    "layer_1_weights = np.load('layer_1_weights.npy')\n",
    "layer_1_bias = np.load('layer_1_bias.npy')\n",
    "output_layer_weights = np.load('output_layer_weights.npy')\n",
    "output_layer_bias = np.load('output_layer_bias.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think the number is :  1\n",
      "What the number actually is :  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See accuracy of individual digits.\n",
    "\n",
    "correct_count = 0\n",
    "batch_counter = 0\n",
    "for batch in ds:\n",
    "    batch_counter += 1\n",
    "    if batch_counter == 1:\n",
    "        i1 = 1\n",
    "        test_image = tf.reshape(np.ceil(tf.image.convert_image_dtype(batch['image'][i1], dtype = 'float32')), 784)\n",
    "        network_1 = tf.math.sigmoid(tf.tensordot(layer_1_weights,  test_image , axes = 1) + layer_1_bias)\n",
    "        network_2 = tf.math.sigmoid(tf.tensordot(output_layer_weights, network_1, axes = 1) + output_layer_bias)\n",
    "        print('I think the number is : ', tf.argmax(network_2).numpy())\n",
    "        print('What the number actually is : ', batch['label'][i1].numpy())\n",
    "        plt.imshow(tf.reshape(test_image, (28, 28)), cmap = 'gray')\n",
    "        \n",
    "# Note that above I have changed the image, such that the gray scale value is only either zero or one.\n",
    "# Which is not what the neural network was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9227666666666666\n"
     ]
    }
   ],
   "source": [
    "# See accuracy with regards to all the data.\n",
    "\n",
    "correct_count = 0\n",
    "batch_counter = 0\n",
    "for batch in ds:    \n",
    "    batch_counter += 1\n",
    "    for i1 in range(batch['image'].shape[0]):\n",
    "        test_image = tf.reshape(np.ceil(tf.image.convert_image_dtype(batch['image'][i1], dtype = 'float32')), 784)\n",
    "#         print(test_image)\n",
    "        network_1 = tf.math.sigmoid(tf.tensordot(layer_1_weights,  test_image , axes = 1) + layer_1_bias)\n",
    "        network_2 = tf.math.sigmoid(tf.tensordot(output_layer_weights, network_1, axes = 1) + output_layer_bias)\n",
    "        if tf.argmax(network_2.numpy()) == batch['label'][i1].numpy():\n",
    "            correct_count += 1\n",
    "print(correct_count / 60000)\n",
    "\n",
    "# Note that above I have changed the image, such that the gray scale value is only either zero or one.\n",
    "# Which is not what the neural network was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save weights and biases.\n",
    "\n",
    "np.save('layer_1_weights.npy',layer_1_weights.numpy())\n",
    "np.save('layer_1_bias.npy', layer_1_bias.numpy())\n",
    "np.save('output_layer_weights.npy', output_layer_weights.numpy())\n",
    "np.save('output_layer_bias.npy', output_layer_bias.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondaf34a0cb157064adcb10e0debffd47a7c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
